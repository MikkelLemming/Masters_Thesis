globals().clear()

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
from astropy.io import fits
import time as t
import random as r
import winsound
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
import tensorflow as tf
from sklearn.preprocessing import StandardScaler
import xgboost
from sklearn.metrics import confusion_matrix
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.model_selection import KFold
from sklearn.neural_network import MLPClassifier




t_0 = t.time()

directory_path = 'C:\\Users\\mikke\\Desktop\\Kandidat_Stuff\\simpaqs-main\\simpaqs-main\\output\\Processed_Data'
DLA = pd.read_csv(directory_path + '\\DLA')
Abs = pd.read_csv(directory_path + '\\Abs_Info')
DF = pd.read_csv(directory_path + '\\Extra_Info')
temp_file_list = os.listdir(directory_path)
temp_file_list = [file for file in temp_file_list if 'Quasar' in file]
sorted_files = sorted(temp_file_list, key=lambda x: int(x.split('Quasar')[-1].split('.')[0]))

#data_generator = (fits.open(directory_path + '\\' + file_name) for file_name in sorted_files[0:4000] if 'Quasar' in file_name)
data_generator = (fits.open(directory_path + '\\' + file_name) for file_name in sorted_files if 'Quasar' in file_name)
#data_set_flux, data_set_wave, scale = 'Flux_gen_15', 'Wave_gen_15', 4/15
#data_set_flux, data_set_wave, scale = 'Flux_gen_5', 'Wave_gen_5', 4/5
data_set_flux, data_set_wave, scale = 'Flux_imp', 'Wave_imp', 4
# Scale is how many datapoints are needed for 1Ã…

X = []
Y = []
Z = []
# Create Flux data
for data, z in zip(data_generator, DF.REDSHIFT):
    X.append(data[1].data[data_set_wave])
    Y.append(data[1].data[data_set_flux])
    Z.append(z)
    data.close()


# Creating DLA_Z data
n = 0
DLA_Z = []
for i in Abs['N_DLA']:
    dla_z = []
    for j in range(i):
        dla_z.append(DLA['Z_ABS'][n])
        n += 1
    DLA_Z.append(dla_z)

# # Hyperparameters
# def Preprocessing(Band_size = 200, Min_DLA_width = 10, DLA_place_lim = 0.8, Incl_n_negs = 8):
 # # Function creating banded data
#     Flux = []
#     Wave = []
#     DLA_Bool = []
#     n = 0
#     for i,data_list in zip(range(len(sorted_files)),data_generator):
#         z = DF.REDSHIFT[i]
#         Ly_lim = (1+z)*912
#         Lya = (1+z)*1215
#         if Lya >= 3674 + Band_size:
#             band_start = max(3674, Ly_lim)
#             j = 0
#
#             if DLA_Z == []:
#                 while band_start + j + Band_size < Lya:
#                     if n == Incl_n_negs:
#                         start, end = round((band_start + j - 3674) * scale), round((band_start + j - 3674 + Band_size) * scale)
#                         Flux.append(data_list[1].data[data_set_flux][start:end])
#                         Wave.append(data_list[1].data[data_set_wave][start:end])
#                         DLA_Bool.append(0)
#                         n = 0
#                     else:
#                         n += 1
#                     j += Band_size/2
#
#             else:
#                 while band_start + j + Band_size < Lya:
#                     start, end = round((band_start+j-3674)*scale),round((band_start+j-3674+Band_size)*scale)
#                     flux = data_list[1].data[data_set_flux][start:end]
#                     wave = data_list[1].data[data_set_wave][start:end]
#                     bool = 0
#                     for Z in DLA_Z[i]:
#                         if band_start + j + (1 - DLA_place_lim) / 2 * Band_size < (Z + 1) * 1215 < band_start + j + Band_size - (1 - DLA_place_lim) / 2 * Band_size:
#                             Z_index = wave.tolist().index(min(wave, key=lambda x: abs(x - (Z + 1) * 1215)))
#                             if all(x <= max(flux) / 2 for x in flux[round(Z_index - scale * 0.5 * Min_DLA_width):round(Z_index - scale * 0.5 * Min_DLA_width)]):
#                                 bool = 1
#                                 break
#
#                     if bool == 0:
#                         if n == Incl_n_negs:
#                             Flux.append(flux)
#                             Wave.append(wave)
#                             DLA_Bool.append(bool)
#                             n = 0
#                         else:
#                             n += 1
#
#                     elif bool == 1:
#                         Flux.append(flux)
#                         Wave.append(wave)
#                         DLA_Bool.append(bool)
#
#                     j += Band_size / 2
#         data_list.close()
#     return Flux, Wave, DLA_Bool

def Data_Splitting(X=X, Y=Y, Z=Z, DLA_Z=DLA_Z, Band_size = 200, Min_DLA_width = 10, DLA_place_lim = 0.8, Incl_n_negs = 8):
# Function creating banded data
    Flux = []
    Wave = []
    DLA_Bool = []
    n = 0
    for i in range(len(X)):
        z = Z[i]
        Ly_lim = (1+z)*912
        Lya = (1+z)*1215
        if Lya >= 3674 + Band_size:
            band_start = max(3674, Ly_lim)
            j = 0

            if DLA_Z == []:
                while band_start + j + Band_size < Lya:
                    if n == Incl_n_negs:
                        start, end = round((band_start + j - 3674) * scale), round((band_start + j - 3674 + Band_size) * scale)
                        Flux.append(Y[i][start:end])
                        Wave.append(X[i][start:end])
                        DLA_Bool.append(0)
                        n = 0
                    else:
                        n += 1
                    j += Band_size/2

            else:
                while band_start + j + Band_size < Lya:
                    start, end = round((band_start+j-3674)*scale),round((band_start+j-3674+Band_size)*scale)
                    flux = Y[i][start:end]
                    wave = X[i][start:end]
                    bool = 0
                    for z in DLA_Z[i]:
                        if band_start + j + (1 - DLA_place_lim) / 2 * Band_size < (z + 1) * 1215 < band_start + j + Band_size - (1 - DLA_place_lim) / 2 * Band_size:
                            Z_index = wave.tolist().index(min(wave, key=lambda x: abs(x - (z + 1) * 1215)))
                            if all(x <= max(flux) / 2 for x in flux[round(Z_index - scale * 0.5 * Min_DLA_width):round(Z_index - scale * 0.5 * Min_DLA_width)]):
                                bool = 1
                                break

                    if bool == 0:
                        if n == Incl_n_negs:
                            Flux.append(flux)
                            Wave.append(wave)
                            DLA_Bool.append(bool)
                            n = 0
                        else:
                            n += 1

                    elif bool == 1:
                        Flux.append(flux)
                        Wave.append(wave)
                        DLA_Bool.append(bool)

                    j += Band_size / 2
    return Flux, Wave, DLA_Bool


Flux, Wave, DLA_Bool = Data_Splitting(Band_size=100, DLA_place_lim=0.9, Min_DLA_width=10, Incl_n_negs=4)
#Flux, Wave, DLA_Bool = Data_Splitting()

try:
    Y = np.array(DLA_Bool)
    X = np.array(Flux)
except:
    Flux_new = []
    m = max([len(Flux[i]) for i in range(len(Flux))])
    for f in Flux:
        while len(f) < m:
            f = np.append(f, sum(f)/len(f))
        Flux_new.append(f)
    Y = np.array(DLA_Bool)
    X = np.array(Flux_new)

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=42)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)


# model = tf.keras.Sequential([
#     # tf.keras.layers.Flatten(),
#     tf.keras.layers.Dense(128, activation='relu'),
#     tf.keras.layers.Dense(128, activation='relu'),
#     tf.keras.layers.Dense(128, activation='relu'),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dense(64, activation='relu'),
#     tf.keras.layers.Dense(32, activation='relu'),
#     tf.keras.layers.Dense(32, activation='relu'),
#     tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer for regression
# ])
# model.compile(optimizer='adam', loss='binary_crossentropy')  # , metrics='accuracy')
# model.fit(X_train_scaled, y_train, epochs=35, batch_size=32, validation_split=0.2)

model = tf.keras.Sequential([
    # tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(256, activation='relu'),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dense(64, activation='relu'),
    tf.keras.layers.Dense(32, activation='relu'),
    tf.keras.layers.Dense(1, activation='sigmoid')
    # Output layer for regression
])
model.compile(optimizer='adam', loss='binary_crossentropy')  # , metrics='accuracy')
model.fit(X_train_scaled, y_train, epochs=35, batch_size=32, validation_split=0.2)

# model = MLPClassifier(hidden_layer_sizes=(256,128,64,128,64,32,1))
# model.fit(X_train_scaled, y_train)
# pred = model.predict(X_test_scaled)

pred_proba = model.predict(X_test_scaled)
pred = [int(np.round(p)[0]) for p in pred_proba]
accuracy = accuracy_score(y_test, pred)
print("Accuracy:", accuracy)
Matrix = confusion_matrix(y_test, pred)
print(Matrix)
print('DLA Accuracy:', Matrix[1][1] / sum(Matrix[1]) * 100, '%')

# #           This is to test how accuret the results that it's sure about are
# pred_sure = []
# y_test_sure = []
# Sureness = 0.3
# for i in range(len(pred_proba)):
#     if pred_proba[i] > 0.5+Sureness or pred_proba[i] < 0.5-Sureness:
#         pred_sure.append(pred[i])
#         y_test_sure.append(y_test[i])
# accuracy = accuracy_score(y_test_sure, pred_sure)
# print("Accuracy its sure abut:", accuracy)
# Matrix = confusion_matrix(y_test_sure, pred_sure)
# print(Matrix)
# print('DLA Accuracy its sure about:', Matrix[1][1] / sum(Matrix[1]) * 100, '%')

false_neg = []
false_pos = []
for i in range(len(pred)):
    if pred[i] == 0 and y_test[i] == 1:
        false_neg.append( [pred_proba[i],i] )
    if pred[i] == 1 and y_test[i] == 0:
        false_pos.append( [pred_proba[i],i] )



plt.show()
print('Took:', t.time()-t_0, 's')
winsound.Beep(440,500)
winsound.Beep(440,750)
winsound.Beep(440,500)



